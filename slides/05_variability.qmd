---
format: revealjs
---

# 5|VARIABILITY

![](covers/05_variability.svg){.invertable}

# Overview

- [Variability]
- [Range]
- [Sum of squares, variance, SD]
- [Degrees of freedom]
- [Learning checks]


# Variability example

Imagine you and a friend got the following scores

```{r}
you <- c(0,4,5,5,6,10)
friend <- c(0,1,5,5,9,10)
```

-   You: `r you`
-   Friend: `r friend`

How would you describe the difference in your performances?

::: fragment
-   Same mode/mean/median
-   But one seems more [variable]{.emph} than the other
:::


## Variability example

:::: {.columns .invertable}
::: {.column .center-element}
![](media/you-dist.svg)

![](media/you-curve.svg){style="margin-top: -0.5em;"}

![](media/leptokurtotic.png){width=70% style="padding-left: 1em; margin-bottom: -0.7em;"}

[Leptokurtotic]{.invertable style="font-size: 0.8em; padding-left: 1em;"}
:::

::: {.column .center-element}
![](media/friend-dist.svg)

![](media/friend-curve.svg){style="margin-top: -0.5em;"}

![](media/platykurtotic.png){width=70% style="padding-left: 1em; margin-bottom: -0.7em;"}

[Platykurtotic]{.invertable style="font-size: 0.8em; padding-left: 1em;"}
:::
::::


## Variability {.small}

-   Like the mean
    -   A [descriptive]{.emph} statistic
    -   Single number to summarize dataset
-   Unlike the mean
    -   Rather than describing the [middle]{.emph} of the data, variability describes the [spread]{.emph} of the data
    -   Higher variability means greater differences between scores
-   Purpose
    -   Quantify how well an individual score represents the distribution
    -   Important for inferential stats


## Measures of variability {.smaller}

-   Quantitative distance measures based on the differences between scores
    -   Each has different characteristics
-   Range
    -   Describes the spread of scores
    -   Distance of most extreme scores from each other
-   $SS$, Variance, and Standard Deviation
    -   Companion concepts, but different things
    -   Describe distance of scores from the mean
    -   Small values: low variability; scores clustered close to mean
    -   Higher values: greater variability; scores widely scattered



# Range

## Range

-   Difference between lowest & highest scores
    -   Distance covered by the scores in a distribution
    -   Range = $X_{max} - X_{min}$

```{r}
print_range <- function(x) {
  paste(max(x), " - ", min(x), " = ", max(x) - min(x))
}
```

- You: `r you`
    - $`r max(you)` - `r min(you)` = `r max(you) - min(you)`$

- Friend: `r friend`
    - $`r max(friend)` - `r min(friend)` = `r max(friend) - min(friend)`$


## Range

-   Characteristics
    -   Does not consider all the data
    -   Based only on two scores: most extreme values
    -   Imprecise, unreliable measure of variability
    -   Not often useful for descriptive/inferential stats
-   But checking range & min/max values can be useful for finding mistakes in data input
    -   Impossible range / min & max values




# Sum of squares, variance, SD

## Definitions {.smaller}

-   Deviation
    -   Distance from the mean: deviation score = $X â€“ \mu$
-   $SS$: Sum of squares
    -   Sum of squared deviations
-   Variance
    -   The mean squared deviation
    -   Average squared distance from the mean
    - [Calculation differs for population and samples]{.emph}
-   Standard deviation
    -   The square root of the variance
    -   Provides a measure of the average (standard) distance of scores from the mean


## Approach {.small}

-   Determine the deviation of each score
    -   Distance from the mean
    -   Deviation score = $X - \mu$

![](media/central-tendency-balance-2.svg){.invertable style="height: 7em; margin-top: -0.5em; margin-bottom: -0.5em;"}

- To find "average deviation" just sum the deviations and divide by $n$?
    - Dead end; always sums to $0$

## Calculations

::: {.columns .fragment}
::: {.column width="60%"}
1.  Find the deviation for each score
:::

::: {.column width="40%"}
$X - \mu$
:::
:::

::: {.columns .fragment}
::: {.column width="60%"}
2.  Square deviations
:::

::: {.column width="40%"}
$(X - \mu)^2$
:::
:::

::: {.columns .fragment}
::: {.column width="60%"}
3.  Sum the squared deviations
:::

::: {.column width="40%"}
$SS = \Sigma(X - \mu)^2$
:::
:::

::: {.columns .fragment}
::: {.column width="60%"}
4.  Find average of squared deviations
:::

::: {.column width="40%"}
$\sigma^2 = \dfrac{SS}N$
:::
:::

::: {.columns .fragment}
::: {.column width="60%"}
5.  Take square root of variance
:::

::: {.column width="40%"}
$\sigma = \sqrt{\sigma^2} = \sqrt{\dfrac{SS}N}$
:::
:::

## Calculating by hand

:::: {.columns}

::: {.column}
```{r}
#| style: "font-size: 0.8em;"
bc1101tools::SD_table(you, population_sd = TRUE)
```
:::

::: {.column}
```{r}
#| style: "font-size: 0.8em;"
bc1101tools::SD_table(friend, population_sd = TRUE)
```
:::

::::

## Sum of squared deviations {.small}

- Very important concept! Especially later

:::: {.columns}

::: {.column}
- Definitional formula
    - Find each deviation score $(X â€“ \mu)$
    - Square each deviation score $(Xâ€“\mu)^2$
    - Sum up the squared deviations $\Sigma(Xâ€“\mu)^2$

::: {.center-element}
$SS = \Sigma(X - \mu)^2$
:::
:::

::: {.column}
- Computational formula
    - Square each score & sum the squared scores
    - Find the sum of scores, square it, divide by $N$
    - Subtract the second part from the first

::: {.center-element}
$SS = \Sigma X^2 - \dfrac{(\Sigma X)^2}N$
:::
:::

::::

# SD & variance for samples {.smaller}

- Research goal:
    - Draw general conclusions about population based on limited information from a sample
- Problem: 
    - Samples have less variability than population they are drawn from
    - Computing the Variance and Standard Deviation in the same way as for a population would give a *biased* estimate of the population parameter
    - Biased estimate: Systematically overestimates or underestimates the parameter
    - Unbiased estimate: Average value of statistic is equal to population parameter
    - Variance & SD for samples [underestimate]{.emph} population parameters

## Underestimation

- Why samples underestimate variability
    - Soup

![](media/soup.jpg)

## Underestimation

- Why samples underestimate variability
    - Height

![](media/height.svg){.invertable}

## Height

::: {#height-container .center-element}
:::

::: {.refresh-sample-button style="position: absolute; left: 50%; transform: translate(-50%, -50%);"}
```{ojs}
//| style: "width: 1.2em; overflow: hidden;"

viewof s = Inputs.button(html`&#x21bb;`)
```
:::

## Calculating variability of samples

- Simple solution: divide $SS$ by $n â€“ 1$ instead of $n$
    - Produces [unbiased]{.emph} estimate of the population variance


## Variability equations for samples

::: {.columns}
::: {.column width="60%"}
1.  Find the deviation for each score
:::

::: {.column width="40%"}
$X - \mu$
:::
:::

::: {.columns}
::: {.column width="60%"}
2.  Square deviations
:::

::: {.column width="40%"}
$(X - \mu)^2$
:::
:::

::: {.columns}
::: {.column width="60%"}
3.  Sum the squared deviations
:::

::: {.column width="40%"}
$SS = \Sigma(X - \mu)^2$
:::
:::

::: {.columns}
::: {.column width="60%"}
4.  Find average of squared deviations
:::

::: {.column width="40%"}
$\sigma^2 = \dfrac{SS} {\color{red}{n-1}}$
:::
:::

::: {.columns}
::: {.column width="60%"}
5.  Take square root of variance
:::

::: {.column width="40%"}
$\sigma = \sqrt{\sigma^2} = \sqrt{\dfrac{SS}{\color{red}{n-1}}}$
:::
:::



# Degrees of freedom {.smaller}

-   Why $n â€“ 1$?\
-   Degrees of freedom
    -   Number of scores in sample that are independent and free to vary
-   Population variance
    -   Mean is known: Deviations are computed from a known mean (not one we had to calculate)
-   Sample variance as estimate of population
    -   Population mean is unknown: We calculate sample mean instead, as an estimate of population parameter
    -   Then use calculated mean to calculate deviations
    -   $df$ is $n$ minus number of population parameter estimates we already calculated

## Degrees of freedom

::: {.r-hstack}
::: {.playing-card}
ðŸ‚ 
:::
::: {.playing-card}
ðŸ‚ 
:::
::: {.playing-card}
ðŸ‚ 
:::
:::

## Degrees of freedom

::: {.r-hstack}
::: {.playing-card}
ðŸƒ“
:::
::: {.playing-card}
ðŸ‚ 
:::
::: {.playing-card}
ðŸ‚ 
:::
:::

## Degrees of freedom

::: {.r-hstack}
::: {.playing-card}
ðŸƒ“
:::
::: {.playing-card}
ðŸƒ•
:::
::: {.playing-card}
ðŸ‚ 
:::
:::

## Degrees of freedom {.smaller}

- Why $n â€“ 1$?
    - $M = 5$
    - $n = 3$
- If you know the first 2 scores:
    - 3, 5
    - $M = \dfrac{\Sigma X}{N} = \dfrac{3 + 5 + X}{3}$
    - So $X = 3*M - 3 - 5 = 7$
- There is only 1 possible value that $X$ can be
    - It is not free to vary
    - We've lost 1 degree of freedom


# Variability example

- SD as a measure of opinion polarization
  - James Oâ€™Malley: [Exclusive: The Most Critically Divisive Films According To Data](http://www.gizmodo.co.uk/2017/11/exclusive-the-most-critically-divisive-films-according-to-data/)
    - (Melancholia, Inception, Sin City)

- Star Wars
  - [The â€œbacklashâ€ against Star Wars: The Last Jedi, explained](https://www.vox.com/culture/2017/12/18/16791844/star-wars-last-jedi-backlash-controversy)
  - â€œWhy the latest film in the galaxy-spanning franchise has proved so unexpectedly polarizing.â€

<!-- ![](media/5-star-wars.png) -->

## Star Wars variability {.smallest}

```{css}
.hide-columns td:nth-of-type(n+5) {
   opacity: 0;
}

.hide-columns th:nth-of-type(n+5) {
   opacity: 0;
}

.hide-columns tr:nth-of-type(1) th:nth-of-type(3) {
   opacity: 0;
}

```

```{r}
sw <- readr::read_csv(here::here("slides", "data", "StarWarsTable_2022-01-31.csv"))

sw <- sw[c(6,5,4,9,8,7,3,2,1),]
rownames(sw) <- NULL

sw_table <- sw |> 
  knitr::kable(format = 'html', digits = 1, escape = F,
             format.args = list(big.mark = ",", scientific = FALSE),
             col.names = c("Movie",rep(c("<i>N</i>","<i>M</i>","<i>SD</i>"), 2))) |> 
  kableExtra::add_header_above(c("", "MetaCritic.com" = 3, "IMDb.com" = 3))
```

:::: {.r-stack}
:::{.hide-columns .fragment .fade-out fragment-index=1}
```{r}
sw_table
```
:::

:::{.fragment fragment-index=1}
```{r}
sw_table
```
:::
::::




# Learning checks

1. Is it possible for a sample to have a standard deviation of zero?

2. A sample of four scores has $SS = 24$. What is the variance?

3. Why do samples systematically have less variability than the population?







::: {.content-hidden}

# Data and figures

## You vs friend plots

```{r example-score-distributions}
#| eval: false

library(ggplot2)
library(bc1101tools)

scale_x <- ggplot2::scale_x_continuous(breaks = 0:10)
scale_y <- ggplot2::scale_y_continuous(expand = ggplot2::expansion(c(0,0.1)), breaks = 0:2)
plot_histogram(you, xlab = "Your scores", block = TRUE) + scale_x + scale_y + theme_bc1101()
plot_save("you-dist.svg", width = 5, height = 1.5)

plot_histogram(friend, xlab = "Friend's scores", block = TRUE) + scale_x + scale_y + theme_bc1101()
plot_save("friend-dist.svg", width = 5, height = 1.5)

plot_distribution() + theme_bc1101() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())
plot_save("you-curve.svg", height = 1)

plot_distribution(args = list(sd = 1.8), xlim = c(-3, 3)) +
  scale_y_continuous(limits = c(0, 0.4), expand = expansion(c(0,0.1))) + theme_bc1101() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())

plot_save("friend-curve.svg", height = 1)

```


## Variability height plot

```{r}
#| eval: false
library(ggplot2)
set.seed(11)
arrows <- data.frame(x = rnorm(10),
                     y = 0, 
                     yend = -.05)

ggplot() +
  stat_function(fun = 'dnorm', geom = 'area', fill = NA, color = 'black', xlim = c(-4, 4)) +
  
  # label population variability with arrow & text
  geom_segment(aes(x = -3.5, xend = 3.5, y = .41, yend = .41),
               linetype = 8, arrow = arrow(length = unit(0.3,"cm"), ends = "both")) +
  annotate(geom = "text", label = "Population variability",
           x = 0, y = .43) +
  
  # draw arrows for random samples
  geom_segment(data = arrows, aes(x=x, xend=x,y=y,yend=yend),
               arrow = arrow(length = unit(0.1,"cm"))) +
  
  # label sample variability with arrow & text
  geom_segment(aes(x = min(arrows$x), xend = max(arrows$x), y = -.07, yend = -.07),
               linetype = 8, arrow = arrow(length = unit(0.3,"cm"), ends = "both")) +
  annotate(geom = "text", label = "Sample variability",
           x = mean(range(arrows$x)), y = -.085) +
  theme_void()

plot_save("height.svg", height = 3)
```

:::

::: {.content-hidden}
## Height
:::


```{ojs}
jStat = require("https://cdn.jsdelivr.net/npm/jstat@latest/dist/jstat.min.js")

sample = {
  s;
  let arr = [];
  for (var i = 0; i < 10; i++) {
    arr.push(jStat.normal.sample(0, 1))
  }
  return arr;
}
```


```{r}
data <- tibble::tibble(value = seq(-4, 4, length.out = 201),
                       density = dnorm(value)) |> 
  purrr::transpose()

ojs_define(data)
```

```{ojs}

w = 800
h = 500
  
x = d3.scaleLinear()
    .domain([-4, 4])
    .range([0, w])
y = d3.scaleLinear()
    .domain([0, 0.41])
    .range([h-100, 0])
line = d3.line()
    .x(d => x(d.value))
    .y(d => y(d.density))
    

update_svg = {
    
  d3.select("#heights-svg").remove()
  
  const svg = d3.select("#height-container")
    .append("svg").attr("id", "heights-svg")
    .attr("width", w).attr("height", h)
  
  const curve = svg.append("path")
      .attr("d", line(data))
      .attr("stroke", "black")
      .attr("stroke-width", 3)
      .attr("fill", "none")
      .attr("class", "invertable")
      
  const g = svg.append("g")

  const circles = g.selectAll("circle")
    .data(sample)
    .enter()
    .append("circle")
      .attr("fill", "lightblue")
      .attr("r", 10)
      .attr("cx", d => x(d))
      .attr("cy", h - 50)
      .attr("opacity", 0)
      .transition().duration(0).delay(function(d, i){return i*50}).attr("opacity", 1)
}

```
