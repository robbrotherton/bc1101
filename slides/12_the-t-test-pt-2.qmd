---
format: revealjs
---

# 12|THE $t$-TEST [part 2]{style="color: #777; float: right;"}

![](covers/12_the-t-test-pt-2.svg){.invertable-blue}


# Overview

- [Research designs]
- [Assumptions]
- [Effect size]
- [Confidence intervals]
- [Learning checks]



# Research designs

- Single-sample $t$-test
  - Compare sample against expected population mean based on logic/theory/scale design

:::: {.columns}

::: {.column width="50%"}
- E.g. 'common sense' theory
  - Population average amount of sleep
:::

::: {.column width="50%" .center-element}
$\mu = 8$ hours
  
![](media/theoretical-distribution.svg){.invertable}
:::

::::


## Research designs

- E.g. measure of happiness

:::: {.columns}

::: {.column width="60%"}

```{r}

bc1101tools::likert("What is your current level of happiness?", 
                    c("1. A lot less than usual",
                      "2. A little less than usual",
                      "3. About average",
                      "4. A little more than usual",
                      "5. A lot more than usual"), 
                    extra_css = "width: 85%; font-size: 0.75em")

```

:::

::: {.column width="40%" .center-element}

$\mu = 3$

![](media/theoretical-distribution.svg){.invertable style="margin-top: 0;"}
:::

::::



# Assumptions {.smaller}

- Assumptions for [single-sample $t$-tests]{.emph}
  1. Independence
      - Independent random sampling
      - Values in the sample are independent observations
  2. Normality
      - The population sampled is normally distributed
      - With large samples $(n > 30)$, this assumption can be violated without affecting the validity of the hypothesis test
  3. Homogeneity of variance
      - Variability in the original and treated populations is the same


# Effect size {.small}

```{r}
r <- function(x) sprintf("%.2f", x)
rt <- bc1101tools::class_reaction_times

n <- length(rt[!is.na(rt)])
M <- mean(rt, na.rm = T)
SD <- sd(rt, na.rm = T)
mu <- 284
d <- (M - mu)/SD

t <- (M-mu) / (SD/sqrt(n))
```


- Hypothesis test Step 4: Make decision (reject null?)
- Step 4b: Evaluate effect size
  - Cohen’s $d$ for single-sample $t$-test
  - Original equation included population SD, $\sigma$
  - Estimated Cohen’s $d$ uses sample SD, $s$

::: {.c .smaller}
$\text{Estimated } d = \dfrac{\text{mean difference}}{\text{sample standard deviation}} = \dfrac{M - \mu}{s}$

$\text{For class RT data, } d = \dfrac{`r r(M)` - `r round(mu, 2)`}{`r r(SD)`} = `r r(d)`$
:::


## Effect size: $r^2$

- Proportion of all variability in the data attributable to treatment effect
- Simplifying assumption: Treatment adds or subtracts a constant to each score
- E.g. 1 point on a scale of 1 to 5
- $r^2$ separates that [variability due to treatment]{.emph} from [natural variability]{.emph} between scores

::: {.c}
$r^2 = \dfrac{SS_{treatment}}{SS_{total}}$
:::


## $r^2$ {.smallest}


:::: {.columns}

::: {.column width="50%"}
1. Calculate sum of squared deviations from sample $M$
    - Variability [excluding]{.emph} treatment effect
    - $SS_{without \ treatment}$
2. Calculate $SS$ from $H_0$ $\mu$
    - This is [total]{.emph} variability
    - $SS_{total}$
3. Substract $SS_{without \ treatment}$ from $SS_{total}$ to find $SS_{treatment}$
    - [Variability attributable to treatment effect]{.emph}
:::

::: {.column width="50%"}
![](media/r-squared-diagram-1.svg){.invertable}

![](media/r-squared-diagram-2.svg){.invertable}
:::

::::

::: {style="margin-top: -1em;"}
$$\begin{align}
r^2 = \dfrac{SS_{treatment}}{SS_{total}} &= \dfrac{SS_{total} - SS_{without \ treatment}}{SS_{total}} \\
&= \dfrac{10-6}{10} = `r (10-6)/10`
\end{align}$$
:::


## $r^2$ {.small}

- If we already calculated $t$…

::: {.c}
$r^2 = \dfrac{t^2}{t^2 + df}$
:::

- Works for any kind of $t$-test
  - Single / related / independent-samples


- Interpreting $r^2$
  - $r^2 = 0.01$:   small effect
  - $r^2 = 0.09$:   medium effect
  - $r^2 = 0.25$:   large effect
  

# Reporting results

> Given the average reaction time for the population of $\mu = `r mu` ms$, according to humanbenchmark.com, a two-tailed single-sample $t$-test suggests that BC1101 students have significantly different reaction times $(M = `r r(M)`$; $SD = `r r(SD)`)$ than the general population; $t(`r n-1`) =$ $`r r(t)`$, $p < .05$, $d = `r r(d)`$.


# Confidence intervals {.smallest}

- Complementary to significance & effect size
- Quantifies [precision]{.emph} of sample estimate
- Comprised of: 
  - [The point estimate]{.emph} 
      - Our best guess of the population parameter 
  - [Margin of error]{.emph} 
      - A range either side of point estimate
      - Indicates the amount of uncertainty surrounding estimate of population mean 
      - Based on desired 'confidence', i.e. range of the distribution
      - E.g. 95%, 99%, 80%, etc...

## Calculating CI boundaries

:::: {.columns}

::: {.column width="50%"}
- So far, we have been specifying $\mu$, calculating $M$ and $s_M$, solving for $t$
- For CI, rearrange to solve for $\mu$
  - Calculate $M$ and $s_M$, specify $t$ (based on desired width of CI —99%, 95%, 90%, 80% etc), solve for $\mu$
:::

::: {.column width="50%"}
::: {.c}
$t = \dfrac{M - \mu}{s_M}$

$\mu = M \pm t * s_M$
:::
:::

::::




## Confidence interval interpretation {.small}

- What does a confidence interval tell us?
  - Indicates precision of parameter estimate
  - “This sample came from a population which would produce sample means which fall within this range 95% of the time”
  - NOT “we are 95% sure the true population mean is within this range”

> "The parameter is an unknown constant and no probability statement concerning its value may be made."[^1]

[^1]: Jerzy Neyman, original developer of confidence intervals

## Factors that affect CI width


::: {#params style="position: absolute; width: 50%"}
```{r}
bc1101tools::input_text("mu", label = "Point estimate: ", value = 0,
                        label_class = "text-input-label",
                        value_class = "text-input-box math",
                        value_style = "width: 3em;")
bc1101tools::input_text("sigma", label = "Variability: ", value = 1,
                        label_class = "text-input-label",
                        value_class = "text-input-box math",
                        value_style = "width: 3em;")

bc1101tools::input_slider("n", label = "n = ", value = 30, min = 2, max = 100, width = "50%")

bc1101tools::input_slider("ci", label = "CI: ", value = 95, min = 0, max = 100, width = "50%")

```

:::


::: {#ci-container}
:::


## CI & NHST {.small}

- $p$ value and CI always agree about statistical significance if CI is $1 – alpha$
  - E.g. $\alpha = .05$ and 95% confidence interval
- If the $p < \alpha$, the confidence interval will not contain the null hypothesis value
- If the confidence interval does not contain the null hypothesis value, the results are statistically significant
- Both significance level and confidence level define a distance from a mean to a limit
  - The distances in both cases are exactly the same

## CI & NHST

# Learning checks

1. What value of $t$ would you expect to see if the null hypothesis is true?
2. Which combination of factors is most likely to produce a significant value for the $t$ statistic?
    - Small mean difference and large sample variability
    - Small mean difference and small sample variability
    - Large mean difference and large sample variability
    - Large mean difference and small sample variability


::: {.content-hidden}

# Data and figures

## Cover

```{r}
#| eval: false

library(ggplot2)

ggplot() +
  stat_function(fun = dnorm, xlim = c(-3,3)) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-2,2), fill = "dodgerblue", alpha = 0.4) +
  theme_void()

bc1101tools::plot_save("12_the-t-test-pt-2.svg", subdir = "covers", width = 10, height = 5)


```


## Sleep

```{r}
#| eval: false

library(bc1101tools)
library(ggplot2)

plot_distribution() +
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = dnorm(0)), linetype = 2) +
  theme_void()

plot_save("theoretical-distribution.svg")


plot_distribution() +
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = dnorm(0)), linetype = 2) +
  geom_text(aes(x = 0, y = dnorm(0)), label = expression(mu==3), vjust = -1) +
  scale_y_continuous(limits = c(0, 0.5)) +
  theme_void()

plot_save("theoretical-happiness-distribution.svg")

```


## r^2 diagrams

```{r}
#| eval: false

library(bc1101tools)
library(ggplot2)

scores <- c(2,4,5,5)
mu <- 3
mean <- mean(scores)
devs <- scores - mean
devs_mu <- scores - mu

plot_histogram(c(2,4,5,5), block = TRUE) +
  geom_segment(aes(x = mean, xend = mean, y = 0, yend = 2), color = "steelblue", linetype = 3) +
  geom_text(aes(x = scores, y = c(1,1,1,2)-.5, label = devs), color = "lightblue", size = 6) +
  geom_text(aes(x = mean, y = 2), label = expression(italic(M)==4), color = "steelblue", vjust = 0, size = 5) +
  scale_y_continuous(breaks = 1:2, expand = expansion(c(0, 0.2))) +
  theme_bc1101()

plot_save("r-squared-diagram-1.svg", width = 4, height = 2)

plot_histogram(c(2,4,5,5), block = TRUE) +
  geom_segment(aes(x = mu, xend = mu, y = 0, yend = 2), color = "red", linetype = 3) +
  geom_text(aes(x = scores, y = c(1,1,1,2)-.5, label = devs_mu), color = "red", size = 6) +
  geom_text(aes(x = mu, y = 2), label = expression(italic(mu)==3), color = "red", vjust = 0, size = 5) +
  scale_y_continuous(breaks = 1:2, expand = expansion(c(0, 0.2))) +
  theme_bc1101()

plot_save("r-squared-diagram-2.svg", width = 4, height = 2)

```

## OJS confidence

:::

```{ojs}

jStat = require("../js/jstat.js")

ci = {

  const w = 1050, h = 600;
  const margin = {bottom: 30};
  const f = d3.format(".2f");
  var mean, sd, confidence, n, std_err, xlim, ci_x_lim;
  
  const x = d3.scaleLinear()
    .domain([-xlim, xlim])
    .range([0, w])
  const y = d3.scaleLinear()
    .domain([0, 0.43])
    .range([h - margin.bottom, 0])
  const line = d3.line()
    .x(d => x(d.value))
    .y(d => y(d.density));
  const xAxis = d3.axisBottom(x);
  
  function makeCurve(xlim) {
    var arr = [];
    var x = jStat(-xlim, xlim, 210)[0];
    for (var i = 0; i < x.length; i++) {
      arr.push({value: x[i], density: jStat.studentt.pdf(x[i], n - 1)})
    }
    return arr
  }
  
  const svg = d3.select("#ci-container").append("svg")
    .attr("width", w).attr("height", h)
    
  const axis = svg.append("g")
    .attr("transform", `translate(0, ${y(0)})`)
    .call(xAxis);
    
  const defs = svg.append("defs")
  const mask = defs.append("mask").attr("id", "mask")
  const mask_rect = mask.append("rect")
  .attr("height", h)
  .style("fill", "white")
  
  const ci_fill = svg.append("path")
    .attr("mask", "url(#mask)")
    .style("stroke", "none").style("fill", "lightblue")
  
  const ci_curve = svg.append("path")
    .attr("class", "invertable")
    .style("stroke", "black")
    .style("fill", "none")
    .style("stroke-width", 4)
  
  const ci_line = svg.append("line")
    .style("stroke", "black").style("stroke-dasharray", [5,5])
    
  const ci_limit_labels = svg.append("g")
  const ci_limit_lower = ci_limit_labels.append("text")
  const ci_limit_upper = ci_limit_labels.append("text").style("text-anchor", "end")
  
  const inputCI =  d3.select("#input-ci")
  const inputN =  d3.select("#input-n")
  const inputMu =  d3.select("#input-mu")
  const inputSigma =  d3.select("#input-sigma")
  
  function initialize() {
    mean = Number(inputMu.property("value"));
    sd = inputSigma.property("value");
    confidence = inputCI.property("value");
    n = inputN.property("value");
    std_err = sd / Math.sqrt(n);
    updateCI();
  }
  
  inputMu.on("input", function() {
    mean = Number(this.value);
    updateCI();
  })
  
  inputSigma.on("input", function() {
    sd = Number(this.value);
    std_err = sd / Math.sqrt(n);
    updateCI();
  })
  
  inputCI.on("input", function() {
    confidence = Number(this.value);
    d3.select("#value-ci").text(confidence);
    
    updateCI();
  })
  
  inputN.on("input", function() {
    n = Number(this.value);
    d3.select("#value-n").text(n);
    std_err = sd / Math.sqrt(n);

    updateCI();
  })

  function updateCI() {
    xlim = sd / std_err;
    x.domain([-xlim, xlim]);
    axis.call(xAxis);
    
    ci_x_lim = jStat.studentt.inv((1 - (confidence/100)) / 2, n - 1);
    var line_height = jStat.studentt.pdf(ci_x_lim, n-1) / 2;
    
    var ci_lims = [mean + ci_x_lim * std_err, mean - ci_x_lim * std_err];
    
    ci_limit_lower
      .text(f(ci_lims[0]))
      .attr("x", x(ci_x_lim))
      .attr("y", y(line_height))
    ci_limit_upper
      .text(f(ci_lims[1]))
      .attr("x", x(-ci_x_lim))
      .attr("y", y(line_height))
    
    ci_fill.attr("d", line(makeCurve(15)))
    ci_curve.attr("d", line(makeCurve(xlim)))
    
    mask_rect
      .attr("x", x(ci_x_lim))
      .attr("width", x(-ci_x_lim) - x(ci_x_lim));
    
    ci_line
      .attr("transform", `translate(0, ${y(line_height)})`)
      .attr("x1", x(-ci_x_lim)).attr("x2", x(ci_x_lim))
  }
  
  initialize();
}

```

