{
  "hash": "b2c9ba3d83a0cd9aa382e8319f5761d0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Problem Set 3\nsubtitle: Describing data\n\nformat: html\nsidebar: recitation\nnavbar: false\nexecute: \n  echo: true\n---\n\n# Part 1: Computing descriptive statistics\n\n::: {.content-hidden when-format=\"pdf\"}\n## Instructions\n\n### Central tendency\n\nSuppose we have a set of values: `1,2,3,3,4,5,10`\n\nThere are several ways you could find the mean. One way would be to add the scores and divide by $N$, like you would on paper.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(1 + 2 + 3 + 3 + 4 + 5 + 10) / 7\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n:::\n\n\nOf course, you don't want to have to type all those numbers and figure out N yourself (especially if you were dealing with a much larger set of numbers). Better to have the scores as a named object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscores <- c(1,2,3,3,4,5,10)\n```\n:::\n\n\nNow life is much easier. The same mathematical approach can be implemented with the `sum()` and `length()` functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(scores)/length(scores) # this is equivalent to Sigma X divided by N\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n:::\n\n\nEven better, R has built-in functions to easily find the mean and median of a set of scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\nmedian(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n:::\n\n\nYou'd think there'd be one for finding the mode as well...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmode(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"numeric\"\n```\n\n\n:::\n:::\n\n\nBut that actually does something different.\n\nSince the mode is a common statistic, though, somebody already wrote a function to compute it. It's in a package called `modeest`. The package contains the function `mfv()`, for \"most frequent value\", which we can now use to get the mode. Remember, since it's an external package, we need to activate it with the `library()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(modeest)\nmfv(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n:::\n\n\nOr equivalently, you can use the double-colon operator to refer to a `package::its_function()` without a separate `library()` call:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodeest::mfv(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n:::\n\n\n### Variability\n\nThere are functions to find the minimum and maximum value in a set of scores. The range is the difference between those:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmin(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\nmax(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10\n```\n\n\n:::\n\n```{.r .cell-code}\nmax(scores) - min(scores) # range\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9\n```\n\n\n:::\n:::\n\n\nR has a built-in functions for sample SD.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.94392\n```\n\n\n:::\n:::\n\n\nThere's also a `var()` function to compute the variance. Remember that standard deviation is the square-root of variance, so if we square the SD it should give the same answer as `var()`...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8.666667\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(scores)^2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8.666667\n```\n\n\n:::\n:::\n\n\nNeato!\n\nNote that these functions return *sample* variance & SD. There are no built-in functions for *population* variance & SD so if you wanted to find them you would have to use the mathematical procedure outlined in the lecture.\n\n### Summarizing a data.frame column\n\nThe above instructions show how mathematical operations and functions can be used to compute summary statistics for a set of numbers. Most often, however, the set of numbers we're dealing with is a column in a data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(scores = c(1,2,3,3,4,5,10))\n```\n:::\n\n\nYou can use the same approaches as above, just remember the `$` notation to refer to a data.frame column:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(df$scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(df$scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.94392\n```\n\n\n:::\n:::\n\n\nHowever, `dplyr` has a powerful `summarize()` function that fits in nicely with the pipe operator.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\ndf |> \n  summarize(mean = mean(scores),\n            median = median(scores),\n            mode = modeest::mfv(scores),\n            min = min(scores),\n            max = max(scores),\n            range = max - min,\n            sd = sd(scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mean median mode min max range      sd\n1    4      3    3   1  10     9 2.94392\n```\n\n\n:::\n:::\n\n\nIn a single pipeline we produce all the summary statistics as a data.frame! Note that because I pipe `df` into the `summarize()` function, `scores` refers specifically to that column in the `df` data.frame object rather than the separate `scores` object I created previously. Note also that I defined the `min` and `max` summary columns, and I was able to refer to *those* new columns within the same single `mutate()` function to compute the `range`.\n:::\n\n# Part 2. Comparing groups\n\n::: {.content-hidden when-format=\"pdf\"}\n### Describing and comparing groups of scores\n\nThe `dplyr::summarize()` approach becomes especially useful when we want to compare groups of scores, such as scores from different experimental groups in a study. In addition to `dplyr` I'll use another related package called `tidyr` here to change the structure of some data, making it easier to summarize and visualize (using `ggplot2`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n```\n:::\n\n\nSuppose we have a data.frame with four columns; a participant ID and scores from experimental condition A, condition B, and condition C.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_wide <- read.csv(\"data/3_demo.csv\")\n\ndemo_wide\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  participant condition_a condition_b condition_c\n1           1           1           3           5\n2           2           2           4           6\n3           3           2           4           6\n4           4           3           5           7\n5           5           3           5           7\n6           6           3           5           7\n7           7           4           6           8\n8           8           4           6           8\n9           9           5           7           9\n```\n\n\n:::\n:::\n\n\nThis is a very common data format. It's called \"wide,\" because each variable gets its own column; the spreadsheet gets wider with each additional variable measured. However, an alternative data structure is \"long\"-formatted data. Rather than having multiple columns for each variable, there would be one column to identify the variable, and a second storing the value. Rather than getting wider, the spreadsheet gets longer, because each participant's responses take up multiple *rows* rather than multiple *columns*. Let's use `tidyr`'s `pivot_longer()` function to show what I mean.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_long <- demo_wide |> \n  pivot_longer(-participant, \n               names_to = \"condition\",\n               values_to = \"score\")\n\ndemo_long\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 27 × 3\n   participant condition   score\n         <int> <chr>       <int>\n 1           1 condition_a     1\n 2           1 condition_b     3\n 3           1 condition_c     5\n 4           2 condition_a     2\n 5           2 condition_b     4\n 6           2 condition_c     6\n 7           3 condition_a     2\n 8           3 condition_b     4\n 9           3 condition_c     6\n10           4 condition_a     3\n# ℹ 17 more rows\n```\n\n\n:::\n:::\n\n\nNote that only the data columns should be pivoted, *not* the participant ID column; that's why the first argument `-participant`, excluded that column from the pivot operation. The result is that the new long-format data.frame has 27 rows in contrast to the original's 9. There are three columns: one for participant, with the value identifying each participant duplicated down the rows; a column named \"condition\" (thanks to the argument `names_to = \"condition\"`) containing the labels `condition_a`, `condition_b` and `condition_c`; and finally a column named `score` containing the recorded values associated with each participant and each condition.\n\nWhy bother? Because now it is very easy to produce summary statistics for the whole dataset broken down into the different groups, using `summarize()`'s special `.by` argument to specify the grouping variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_long |> \n  summarize(mean = mean(score),\n            median = median(score),\n            mode = modeest::mfv(score),\n            sd = sd(score),\n            .by = condition)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  condition    mean median  mode    sd\n  <chr>       <dbl>  <int> <int> <dbl>\n1 condition_a     3      3     3  1.22\n2 condition_b     5      5     5  1.22\n3 condition_c     7      7     7  1.22\n```\n\n\n:::\n:::\n\n\nIt is also a breeze to make graphs showing the distribution of the data grouped by condition. In this case, the column identifying which condition a score came from becomes another \"aesthetic\" in the `aes()` function–`color`, meaning the color of the lines and points.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_long |> \n  ggplot(aes(x = score, color = condition)) +\n  geom_freqpoly(binwidth = 1) +\n  geom_point(stat = \"count\")\n```\n\n::: {.cell-output-display}\n![](problem-set-3-instructions_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nYou can also take summarized data and pipe it straight into ggplot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemo_long |> \n  summarize(mean = mean(score),\n            sd = sd(score),\n            .by = condition) |> \n  ggplot(aes(x = condition, y = mean)) +\n  geom_col() +\n  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.3)\n```\n\n::: {.cell-output-display}\n![](problem-set-3-instructions_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nNote that I used `geom_col()` rather than `geom_bar()`, and `geom_errorbar()` required a couple of extra aesthetics to determine the min and max y positions, as well as an argument determining the `width` of the tops and bottoms of the errorbars.\n:::\n",
    "supporting": [
      "problem-set-3-instructions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}