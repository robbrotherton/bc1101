{
  "hash": "3ba5701758889f2b13a8d6a1b3c63f18",
  "result": {
    "markdown": "---\nformat: revealjs\n---\n\n\n# [13|INDEPENDENT-SAMPLES $t$-TEST]{.r-fit-text}\n\n![](covers/11_the-t-test.svg)\n\n# Overview\n\n- [Research design]\n- [Calculation]\n- [Hypothesis test]\n- [Learning checks]\n\n\n# Research design\n\n## Single-sample $t$-test design\n\n- Compare sample against expected population mean based on logic/theory/scale design\n- E.g. give everyone $10\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n::: {#likert-container .smallest style=\"width: 80%; display: block;\"}\n\nWhat is your current level of happiness?\n\n1. A lot less than usual\n2. A little less than usual\n3. About average\n4. A little more than usual\n5. A lot more than usual\n\n:::\n\n:::\n\n::: {.column width=\"40%\" .center-element}\n\n$\\mu = 3$\n\n![](media/theoretical-distribution.svg){.invertable style=\"margin-top: 0;\"}\n:::\n\n::::\n\n\n```{ojs}\nimport {likert} from \"../ojs/utils.qmd\";\n```\n\n\n\n## Single-sample $t$-test logic\n\n::: {style=\"width: 60%; position: relative; font-size: 0.7em; margin-top: 2em; margin-left: 50%; transform: translateX(-50%);\"}\n\n:::: {#nhst-diagram}\n::: {#lines}\n:::\n::: {#treatment}\n:::\n::: {#circle style=\"border: 2px dashed\"}\nPartially known  \noriginal population    \n$\\mu$\n:::\n::: {#circle style=\"right: 0; background-color: lightblue; border: 2px dashed\"}\nUnknown  \ntreated  \npopulation\n:::\n::: {#rect}\nSample\n:::\n::: {#rect style=\"right: 0; background-color: lightblue;\"}\nTreated sample \n$n, M, SD$\n:::\n::: {#population-comparison-line}\n:::\n::::\n:::\n\n\n\n## Independent-samples design {.small}\n\nWhat if... give everyone $10\n\n\n:::: {.columns .c}\n\n::: {.column width=\"50%\"}\nGroup A:  \nSpend this on [yourself]{.emph}\n\n::: {#likert-container .smallest style=\"width: 80%; display: block; text-align: left;\"}\n\nWhat is your current level of happiness?\n\n1. A lot less than usual\n2. A little less than usual\n3. About average\n4. A little more than usual\n5. A lot more than usual\n\n:::\n:::\n\n::: {.column width=\"50%\"}\nGroup B:  \nSpend this on [someone else]{.emph}\n\n::: {#likert-container .smallest style=\"width: 80%; display: block; text-align: left;\"}\n\nWhat is your current level of happiness?\n\n1. A lot less than usual\n2. A little less than usual\n3. About average\n4. A little more than usual\n5. A lot more than usual\n\n:::\n:::\n\n::::\n\n::: {.reference}\nDunn, E. W., Aknin, L. B., & Norton, M. I. (2014). Prosocial spending and happiness: Using money to benefit others pays off. *Current Directions in Psychological Science, 23(1)*, 41-47. [https://doi.org/10.1177/0963721413512503](https://doi.org/10.1177/0963721413512503)\n:::\n\n\n\n## Independent-samples $t$-test logic\n\n::: {style=\"width: 60%; position: relative; font-size: 0.7em; margin-top: 2em; margin-left: 50%; transform: translateX(-50%);\"}\n\n:::: {#nhst-diagram}\n::: {#lines}\n:::\n::: {#treatment}\n:::\n::: {#circle style=\"border: 2px dashed\"}\nUnknown  \ntreated population  \nA\n:::\n::: {#circle style=\"right: 0; border: 2px dashed;\"}\nUnknown  \ntreated population  \nB\n:::\n::: {#rect style=\"background-color: lightblue; color: var(--text-color-light);\"}\nSample A  \n$n, M, SD$\n:::\n::: {#rect style=\"right: 0; background-color: lightblue; color: var(--text-color-light);\"}\nSample B  \n$n, M, SD$\n:::\n::: {#population-comparison-line}\n:::\n::::\n:::\n\n\n# Calculation {.small}\n\nBasic structure of all $t$-tests:\n\n::: {.c}\n$t = \\dfrac{ \\text{sample statistic} - \\text{population parameter} }{\\text{estimated standard error}}$\n<br><br>\n$t = \\dfrac{ \\text{how different was observed from predicted?} }{\\text{how big a difference would we expect by chance?}}$\n<br><br>\n$t = \\dfrac{ \\text{data} - \\text{hypothesis} }{\\text{error}}$\n:::\n\n\n:::: {.columns .c}\n\n::: {.column width=\"50%\"}\nSingle-sample $t$\n\n$t = \\dfrac{M-\\mu}{s_M}$\n:::\n\n::: {.column width=\"50%\"}\nIndependent-samples $t$\n\n$t = \\dfrac{(M_1-M_2)-(\\mu_1-\\mu_2)}{s_{M_1-M_2}}$\n:::\n\n::::\n\n\n## Equations {.small}\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n- Denominator: $s_{M_1-M_2}$\n  - Estimated standard error of the mean difference<br><br>\n:::\n\n::: {.column width=\"50%\"}\n$s_{M_1-M_2} = \\sqrt{\\dfrac{s_p^2}{n_1}+\\dfrac{s_p^2}{n_2}}$\n:::\n::::\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n- $s_p^2$: Pooled variance\n  - Weighted average of two sample variances\n:::\n\n::: {.column width=\"50%\" style=\"margin-left: -4em;\"}\n$\\begin{align} s_p^2 = &\\dfrac{SS_1+SS_2}{df_1+df_2} \\\\ \\\\ \\text{or... } &\\dfrac{df_1*s_1^2 + df_2*s_2^2}{df_1+df_2} \\\\ \\text{because... } s^2 = &\\dfrac{SS}{df} \\text{ so... } SS = df*s^2 \\end{align}$\n:::\n::::\n\n## Calculating independent samples $t$\n\n1. Pooled variance: $s_p^2 = \\dfrac{SS_1+SS_2}{df_1+df_2}$\n2. Estimated standard error of mean difference: $s_{M_1-M_2} = \\sqrt{\\dfrac{s_p^2}{n_1}+\\dfrac{s_p^2}{n_2}}$\n3. $t$ statistic: $t = \\dfrac{(M_1-M_2)-(\\mu_1-\\mu_2)}{s_{M_1-M_2}}$\n\n\n# Hypothesis test\n\n## Step 1: State hypotheses\n\n- Null: There is no difference between groups\n  - The treatment has no effect\n  - $μ_1 – μ_2 = 0$\n- Alternative: There is a difference\n  - The treatment has an effect\n  - Directional: $μ_1 – μ_2 < 0$ or $μ_1 – μ_2 > 0$\n  - Nondirectional: $μ_1 – μ_2 \\ne 0$\n\n## Step 2: Define critical region\n\n- Depends on $\\alpha$ and $df$\n\n$$\n\\begin{align}\ndf &= df_1 + df_2 \\\\\n&= (n_1 – 1) + (n_2 – 1) \\\\\n&= N - 2\n\\end{align}\n$$\n\n## Step 3: Collect data, calculate $t$ statistic\n\n\n::: {.cell}\n\n:::\n\n\n## Step 3 : Calculate $t$ statistic\n\n$s_p^2 = \\dfrac{SS_1+SS_2}{df_1+df_2} = \\dfrac{10 + 8}{4 + 4} = 2.25$\n\n\n$s_{M_1-M_2} = \\sqrt{\\dfrac{s_p^2}{n_1}+\\dfrac{s_p^2}{n_2}} = \\sqrt{\\dfrac{2.25}{5}+\\dfrac{2.25}{5}} = 0.95$\n\n$t = \\dfrac{(M_1-M_2)-(\\mu_1-\\mu_2)}{s_{M_1-M_2}} = \\dfrac{3 - 4}{0.95} = -1.05$\n\n\n## Step 4: Make decision\n\n\n## Step 4b: Effect size\n  - Not required for nonsignificant differences\n\n## Step 5: Report results\n\n“A two-tailed independent-samples $t$ test suggested that the difference in average happiness between people in the \"Spend on self group\" $(M = 3$; $SD = 1.58)$ and the \"Spend on other\" group $(M = 4$; $SD = 1.41)$ was nonsignificant; $t(8) =$ $-1.05$, $p > .05$.”\n\n\n# Assumptions\n\nAssumptions for independent-samples $t$-tests\n\n1. The observations within each sample must be independent\n2. The two populations from which the samples are selected must be normal\n    - Can be ignored with large enough sample size\n3. The two populations from which the samples are selected must have equal variances\n    - Homogeneity of variance \n    - Because pooled variance is a weighted average\n\n## Homogeneity of variance\n\n- Testing the homogeneity of variance assumption\n  - Hartley’s F-max test\n\n::: {.center-element}\n$F_{max} = \\dfrac{s^2_{largest}}{s^2_{smallest}}$\n:::\n\n- Small value (near 1) indicates similar sample variances, larger values indicate larger difference\n- Look up associated critical value for $F$-max test\n- If value exceeds critical value, indicates homogeneity assumption has been violated\n\n## Homogeneity of variance correction\n\n- If homogeneity of variance assumption is violated...\n  - Calculate standard error without pooled variance\n  - Adjust $df$ using equation:\n\n::: {.center-element}\n$$df = \\dfrac{(\\dfrac{s_1^2}{n_1}+\\dfrac{s_2^2}{n_2})}\n{\\dfrac{(\\dfrac{s_1^2}{n_1})^2}{n_1-1} + \\dfrac{(\\dfrac{s_2^2}{n_2})^2}{n_2-1}\n}$$\n:::\n\n## Homogeneity of variance correction\n\n- …or let R do the work for you\n    - `t.test()` function automatically applies correction\n    - Specify `var.equal = TRUE` to override\n\n\n:::: {.columns .small}\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nconditionA <- c(1, 5, 2, 4, 3)\nconditionB <- c(5, 5, 2, 5, 3)\n\nt.test(x = conditionA, y = conditionB)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  conditionA and conditionB\nt = -1.0541, df = 7.9024, p-value = 0.323\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.192378  1.192378\nsample estimates:\nmean of x mean of y \n        3         4 \n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nconditionA <- c(1, 5, 2, 4, 3)\nconditionB <- c(5, 5, 2, 5, 3)\n\nt.test(x = conditionA, y = conditionB, \n       var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  conditionA and conditionB\nt = -1.0541, df = 8, p-value = 0.3226\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.187668  1.187668\nsample estimates:\nmean of x mean of y \n        3         4 \n```\n:::\n:::\n\n:::\n\n::::\n\n# Confidence interval\n\n- Quantifies precision of our statistic\n  - Distribution of differences between two samples drawn from a population with a given standard error of the mean difference\n\n::: {.center-element}\n$t = \\dfrac{(M_1-M_2)-(\\mu_1-\\mu_2)}{s_{M_1-M_2}}$\n\n$(\\mu_1-\\mu_2) = (M_1-M_2) \\pm t * s_{M_1-M_2}$\n:::\n\n# Learning checks\n\n1. What values of $t$ would you expect to see if the null hypothesis is true?\n2. Which combination of factors is most likely to produce a significant value for an independent-measures $t$ statistic?\n  - Small mean difference and large sample variances\n  - Small mean difference and small sample variances\n  - Large mean difference and large sample variances\n  - Large mean difference and small sample variances\n\n\n\n::: {.content-hidden}\n\n# Data and figures\n\n## NHST diagrams\n\n::: {.cell}\n\n:::\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}