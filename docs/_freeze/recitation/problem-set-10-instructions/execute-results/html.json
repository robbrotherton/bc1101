{
  "hash": "46ec50a5534a42e1eaa32118b81ed0c0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Problem Set 10\nsubtitle: Correlation and Regression\n\nformat: html\nsidebar: recitation\nnavbar: false\nexecute: \n  echo: true\n---\n\n# Part 1: Computing and graphing associations\n\n::: {.content-hidden when-format=\"pdf\"}\n## Instructions\n\n### Correlation\n\nR has two basic functions for calculating correlations: `cor()`, and `cor.test()` . They each require two arguments, named `x` and `y`, referring to the two variables (i.e. columns of data) we want to compute the correlation between.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# first read in the relevant data; for this example it's a spreadsheet with two\n# columns, named x and y\ndf <- read.csv(\"data/10_example.csv\")\n\ncor(df$x, df$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.09394529\n```\n\n\n:::\n\n```{.r .cell-code}\ncor.test(df$x, df$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  df$x and df$y\nt = -0.2669, df = 8, p-value = 0.7963\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.6831623  0.5693588\nsample estimates:\n        cor \n-0.09394529 \n```\n\n\n:::\n:::\n\n\nAs you will see, `cor()` simply returns the value of Pearson's $r$. `cor.test()` returns all the information you need to complete a significance test, i.e. the correlation coefficient, degrees of freedom, and $p$-value as well as some stuff you can ignore for our purposes, such as $t$ and a confidence interval.\n\n### Regression\n\nThe `lm()` function computes a 'linear model', i.e. the kind of linear regression model that we have learned about in the lectures. Rather than accepting `x` and `y` arguments, the regression function requires a `formula`, just like you've used with `t.test()` and `aov()` in previous problem sets. The idea is the same here: we articulate a formula in the form `DV ~ IV`. In this context, the DV is the outcome variable, i.e. the one we want to predict. The IV is the predictor. And remember, I'm using `DV` and `IV` generically here: when you write your code you will replace them with the names of columns in your data.frame.\n\nThere is a second step though. Since `lm()` doesn't give us all the information about the regression model that we usually need to report, we assign the model (the output of the `lm()` function) to a name (`model`, in my case), and then we feed that into the `summary()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(y ~ x, data = df)\n\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9279 -1.1678 -0.3557  1.1487  3.2374 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  5.94165    2.02778   2.930    0.019 *\nx           -0.09411    0.35262  -0.267    0.796  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.171 on 8 degrees of freedom\nMultiple R-squared:  0.008826,\tAdjusted R-squared:  -0.1151 \nF-statistic: 0.07123 on 1 and 8 DF,  p-value: 0.7963\n```\n\n\n:::\n:::\n\n\n### Visualizing correlation & regression\n\nTo visualize bivariate correlations, you can use ggplot, specifying your x and y variables as aesthetics, and adding a `geom_point()` layer for the dots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(df, aes(x = x, y = y)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](problem-set-10-instructions_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nTo make this a visualization of the regression model as well, we can simply add another layer to show the best fit line. This is computed by `geom_smooth`. We just need to tell it the `method` we want it to use to compute the line. For our purposes, `method = \"lm\"` meaning \"linear model\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](problem-set-10-instructions_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n:::\n\n# Part 2. The World Happiness Report.\n\n::: {.content-hidden when-format=\"pdf\"}\n## Instructions\n\nFor this question you will work with some real data from the [World Happiness Report](https://worldhappiness.report/).\n\nLook at the data after you read it into R to get an idea of what variables it contains. The column names generally give a clear indication of what the scores are, but some may be unclear or unfamiliar. There's a full explanation at [in the WHR appendix here.](https://happiness-report.s3.amazonaws.com/2024/Ch2+Appendix.pdf){.uri}\n\nYou'll be using `cor()` and/or `cor.test()` to examine correlations. The only new thing to be aware of is that, if you try to correlate two variables and there is even a single missing data point (indicated by `NA`), you will get an answer of `NA`. To avoid this, you can specify `use = \"pairwise.complete.obs` as an argument within either function. That will cause R to ignore cases where one data point is missing, and use however many have complete data for both variables.\n:::\n\n:::: {.content-hidden when-format=\"pdf\"}\n::: {.callout-tip collapse=\"false\"}\n## Or...\n\nSince you're coming to the end of this journey with R, and you're becoming an expert at doing so many things with it, I want to give you the chance to spread your wings and fly. If you want to put your skills to the test and push your limits, please ignore the following questions and just do something cool with the world happiness data. You might produce a visual ranking the happiness of every country, make a map showing happiness around the world (yes, R can do maps!), graph changes over time (`10_world_happiness_all_years.csv` has data for multiple years whereas `10_world_happiness_2023.csv` is just that one year), or something else that I haven't even thought of. Maybe chatGPT can help get you started with ideas and code. Prof B would love to help as well. This is your chance to shine!\n\nOr you can just ignore this and play it safe with the questions below. Your choice; no judgement ðŸ˜Š\n:::\n::::\n",
    "supporting": [
      "problem-set-10-instructions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}